
#' @title Correlation Plots
#'
#' @description Plots for visualizing correlation between estimated
#' discriminant vectors for pairwise data.
#'
#' @param Xtestdata A list with each entry containing views of size
#' \eqn{ntest \times p_d}, where \eqn{d = 1, \dots, D}.Rows are samples
#'  and columns are variables. Can use testing or training data
#' @param Ytest \eqn{ntest \times 1} vector of class membership.
#' @param hatalpha A list of estimated sparse discriminant vectors for each view.
#' @param method.used A character specifying the integration method used. These are used for appropriate labeling.
#' Options are "SIDA" and "SELPCCA". Default is "SIDA"
#' @param color.palette  character vector of length K (number of classes), specifying the colors to use for the classes, respectively.
#' Defaults to shades of blue and orange (color.BlueOrange). Other option includes red and green combinations (color.GreenRed)
#' @param plotIt boolean; if TRUE, plots the plots. If FALSE, only returns the plots. This is useful to customize the ggplots.
#'
#' @details The function will return either a single ggplot (n views == 2), or a list of ggplots (n views > 2). 
#'
#' @return
#' \item{ggplot}{}
#'
#' @seealso \code{\link{cvSIDA}} \code{\link{sidatunerange}}
#' \code{\link{DiscriminantPlots}}
#'
#' @references
#' Sandra E. Safo, Eun Jeong Min, and Lillian Haine (2022), Sparse Linear Discriminant
#' Analysis for Multi-view Structured Data, Biometrics.
#' @import ggplot2
#' @export
#' @examples
#' \dontrun{
#'  #call sida
#' data(sidaData)
#' ##---- call sida algorithm to estimate discriminant vectors, and predict on testing data
#'
#' Xdata=sidaData[[1]]
#' Y=sidaData[[2]]
#' Xtestdata=sidaData[[3]]
#' Ytest=sidaData[[4]]
#'
#' #call sidatunerange to get range of tuning parameter
#' ngrid=10
#' mytunerange=sidatunerange(Xdata,Y,ngrid,standardize=TRUE,weight=0.5,withCov=FALSE)
#'
#' # an example with Tau set as the lower bound
#' Tau=c(mytunerange$Tauvec[[1]][1], mytunerange$Tauvec[[2]][1])
#' mysida=sida(Xdata,Y,Tau,withCov=FALSE,Xtestdata=Xtestdata,Ytest=Ytest,AssignClassMethod='Joint',
#'             plotIt=FALSE, standardize=TRUE,maxiteration=20,weight=0.5,thresh= 1e-03)
#'
#' test.error=mysida$sidaerror
#' test.correlation=mysida$sidacorrelation
#'
#' #estimated discriminant vectors and predicted class
#' hatalpha=mysida$hatalpha
#'
#' predictedClass=mysida$PredictedClass
#'
#' ##----plot discriminant and correlation plots
#' #---------Correlation plot
#' CorrelationPlots(Xtestdata,Ytest,mysida$hatalpha)
#' }
#'
CorrelationPlots=function(Xtestdata=Xtestdata,Ytest=Ytest,hatalpha=hatalpha,
                          method.used="SIDA",color.palette=NULL,
                          plotIt = TRUE){

  if(is.null(color.palette)){
    color.palette=color.BlueOrange(length(unique(Ytest)))
  }
  # determine number of correlations to make
  dsizes=lapply(Xtestdata, function(x) dim(x))
  D=length(dsizes)
  mycomb=t(utils::combn(D, 2, FUN = NULL, simplify = TRUE))

  Classes = factor(Ytest)
  # make ggplots for each plot and add them to a list
  plots = lapply(1:dim(mycomb)[1],
                 FUN = function(d){
                   dd=mycomb[d,]
                   Scoresd=scale(Xtestdata[[dd[1]]])%*%hatalpha[[dd[1]]]
                   Scoresj=scale(Xtestdata[[dd[2]]])%*%hatalpha[[dd[2]]]
                   Scores=cbind.data.frame(Scoresd[,1], Scoresj[,1], Ytest)
                   colnames(Scores)=c("Disc1", "Disc2", "Class")
                   
                   #calculate RV coefficient
                   X1=scale(Xtestdata[[dd[1]]])%*%hatalpha[[dd[1]]]
                   X2=scale(Xtestdata[[dd[2]]])%*%hatalpha[[dd[2]]]
                   X1=scale(X1, center=TRUE,scale=FALSE)
                   X2=scale(X2, center=TRUE,scale=FALSE)
                   X1X2=t(X1)%*%X2/dim(X1)[1]
                   X1X1=t(X1)%*%X1/dim(X1)[1]
                   X2X2=t(X2)%*%X2/dim(X2)[1]
                   RVCoeff=sum(diag(X1X2%*%t(X1X2)))/(sqrt(sum(diag(X1X1%*%X1X1)))*sqrt(sum(diag(X2X2%*%X2X2))))
                   RVCoeff=round(RVCoeff,digits=2)
                   ggplot2::ggplot(Scores, aes(Scores[,1], Scores[,2])) +
                     geom_point(aes(shape=Classes,colour = Classes),size=4) +
                     xlab(
                       if(method.used=="SIDA"){
                         paste(
                           "First Discriminant Score for View ", dd[1])
                       }else if(method.used=="SELPCCA"){
                         paste("First Canonical Variate for View ",dd[1])
                       }
                     )+
                     ylab(
                       if(method.used=="SIDA"){
                         paste(
                           "First Discriminant Score for View ", dd[2])
                       }else if(method.used=="SELPCCA"){
                         paste("First Canonical Variate for View ",dd[2])
                       }
                     )+
                     ggtitle(paste("Correlation plot for views",dd[1], "and" ,dd[2],",", "\u03C1 =", RVCoeff)) +
                     scale_colour_manual(values=color.palette) +
                     scale_fill_manual(values = color.palette) +
                     theme_bw() +
                     theme(axis.title = element_text(face="bold"))+
                     theme(axis.text = element_blank())+
                     theme(axis.ticks.x = element_blank())+
                     theme(axis.ticks.y=element_blank())+
                     theme(axis.ticks = element_blank())
                 })

  if (plotIt){
    if (length(plots) == 1){
      print(plots[[1]])
    }else{
      gridExtra::grid.arrange(grobs = plots)
    }
    return()
  }
  # return the actual ggplot fit if there was only one; otherwise,
  # return a list of ggplot objects, and a message to print using grid.arrange()
  if (length(plots) == 1){
    return(plots[[1]])
  }
  message(">1 data views, returning list of ggplot objects.
          show the output of this function with:
              plots = CorrelationPlots(...)
              gridExtra::grid.arrange(grobs = plots)")
  return(plots)
}



#' @title Discriminant Plots
#'
#' @description Plots discriminant scores (for SIDA) and canonical variates (for
#' SELPCCA) for visualizing class separation
#'
#' @param Xtestdata A list with each entry containing views of size
#' \eqn{ntest \times p_d}, where \eqn{d = 1, \dots, D}. Rows are samples and
#' columns are variables. Can use testing or training data.
#' @param Ytest \eqn{ntest \times 1} vector of class membership.
#' @param hatalpha A list of estimated sparse discriminant vectors for each view.
#' @param method.used A character specifying the integration method used. These are used for appropriate labeling.
#' Options are "SIDA" and "SELPCCA". Default is "SIDA". For SELPCCA, ncancorr \eqn{\ge 2}. If ncancorr \eqn{> 2},
#' plot will be generated for the first two canonical variates.
#' @param color.palette  character vector of length K (number of classes), specifying the colors to use for the classes, respectively.
#' Defaults to shades of blue and orange (color.BlueOrange). Other option includes red and green combinations (color.GreenRed)
#' @param plotIt boolean, if TRUE, prints the plots. If FALSE, returns the ggplots as an object or list.  This is useful to customize the ggplots.
#' @details The function will return discriminant plots.
#'
#' @return
#' \item{NULL}{}
#'
#' @seealso \code{\link{cvSIDA}} \code{\link{sidatunerange}}
#' \code{\link{CorrelationPlots}}
#'
#' @references
#' Sandra E. Safo, Eun Jeong Min, and Lillian Haine (2023), Sparse Linear Discriminant
#' Analysis for Multi-view Structured Data, Biometrics.
#'
#' @import ggplot2
#' @export
#' @examples
#' \dontrun{
#'  #call sida
#' data(sidaData)
#' ##---- call sida algorithm to estimate discriminant vectors, and predict on testing data
#'
#' Xdata=sidaData[[1]]
#' Y=sidaData[[2]]
#' Xtestdata=sidaData[[3]]
#' Ytest=sidaData[[4]]
#'
#' #call sidatunerange to get range of tuning parameter
#' ngrid=10
#' mytunerange=sidatunerange(Xdata,Y,ngrid,standardize=TRUE,weight=0.5,withCov=FALSE)
#'
#' # an example with Tau set as the lower bound
#' Tau=c(mytunerange$Tauvec[[1]][1], mytunerange$Tauvec[[2]][1])
#' mysida=sida(Xdata,Y,Tau,withCov=FALSE,Xtestdata=Xtestdata,Ytest=Ytest,AssignClassMethod='Joint',
#'             plotIt=FALSE, standardize=TRUE,maxiteration=20,weight=0.5,thresh= 1e-03)
#'
#' test.error=mysida$sidaerror
#' test.correlation=mysida$sidacorrelation
#'
#' #estimated discriminant vectors and predicted class
#' hatalpha=mysida$hatalpha
#'
#' predictedClass=mysida$PredictedClass
#'
#' ##----plot discriminant plots
#' #---------Discriminant plot
#' mydisplot=DiscriminantPlots(Xtestdata,Ytest,mysida$hatalpha)
#' }
DiscriminantPlots=function(Xtestdata=Xtestdata,Ytest=Ytest,
                           hatalpha=hatalpha,method.used="SIDA",
                           color.palette=NULL, plotIt = TRUE){


  dsizes=lapply(Xtestdata, function(x) dim(x))
  D=length(dsizes)

  nc=unique(Ytest)
  if(is.null(color.palette)){
    color.palette=color.BlueOrange(length(nc))
  }

  plots = list()
  if(length(nc)==2){
    plots = lapply(1:D,
                   FUN = function(d){
                     
                     if(method.used=="SIDA"){
                       myScores=scale(Xtestdata[[d]])%*%hatalpha[[d]]
                       xlabel = "First Discriminant Score"
                     }else if(method.used=="SELPCCA"){
                       myScores=scale(Xtestdata[[d]])%*%as.data.frame(hatalpha[[d]])[,1]
                       xlabel = "First Canonical Variate"
                     }
                     data.frame(score = myScores, 
                                class = Ytest) %>%
                       dplyr::mutate(class = factor(class)) %>%
                       ggplot(aes(x = score, color = class))+
                       geom_point(aes(y = 0), shape = "|")+
                       geom_density(outline.type = "upper",
                                    trim = FALSE, show.legend = FALSE)+
                       scale_colour_manual(values=color.palette) +
                       labs(x = xlabel,
                            y = "Density",
                            title = paste("Discriminant Plot for View",d))+
                       theme_bw() +
                       theme(axis.title = element_text(face="bold"))+
                       theme(legend.position = c(0.1,0.5),
                             legend.key.height = unit(1, "mm"),
                             legend.background = element_rect(color = "darkgray"))
                   }
    )
  }else if(length(nc)>2){

    Classes=factor(Ytest)
    
    plots = lapply(1:D,
                   FUN = function(d){
                     if(method.used=="SIDA"){
                       Scores=cbind.data.frame(Ytest,
                                               scale(Xtestdata[[d]])%*%hatalpha[[d]])
                       xlabel = paste("First Discriminant Score for View", d)
                       ylabel = paste("Second Discriminant Score for View", d)
                     }else if(method.used=="SELPCCA"){
                       Scores=cbind.data.frame(Ytest,scale(Xtestdata[[d]])%*%as.data.frame(hatalpha[[d]])[,1],
                                               scale(Xtestdata[[d]])%*%as.data.frame(hatalpha[[d]])[,2])   
                       xlabel = paste("First Canonical Variate for View", d)
                       ylabel = paste("Second Canonical Variate for View", d)
                     }
                     ggplot2::ggplot(Scores[,-1], aes(Scores[,2], Scores[,3])) +
                       geom_point(aes(shape=Classes,colour = Classes),size=4) +
                       labs(x = xlabel,
                            y = ylabel,
                            title = paste("Discriminant Plot for View",d))+
                       scale_colour_manual(values=color.palette) +
                       scale_fill_manual(values = color.palette) +
                       theme_bw() +
                       stat_ellipse(aes(Scores[,2], Scores[,3], color=Classes, fill = Classes),
                                    type = "norm", geom = "polygon", alpha = 0.1)+
                       guides(colour = guide_legend(override.aes = list(size=5))) +
                       scale_size_continuous(range=c(10,15))+
                       theme(axis.title = element_text(face="bold"))+
                       theme(axis.text = element_blank())+
                       theme(axis.ticks.x = element_blank())+
                       theme(axis.ticks.y=element_blank())+
                       theme(axis.ticks = element_blank())
                   }
    )
  }
  if (plotIt){
    if (length(plots) == 1){
      print(plots[[1]])
    }else{
      gridExtra::grid.arrange(grobs = plots)
    }
    return()
  }
  return(plots)
}


#' @title Loadings Plots
#'
#' @description Plots discriminant and canonical vectors  to visualize how
#' selected variables contribute to the first and second discriminant (for SIDA and SIDANet)
#' or canonical correlation (for SELPCCA) vectors.  Variables farther from the origin and close to first or second axis
#' have higher impact on first or second discriminant/canonical vectors, respectively.
#' Variables farther from the origin and between both first and second axes have similar higher contributions to the
#' first and second discriminant/canonical correlation vectors. In both situations, for SIDA and SIDANet, this suggests that
#' these variables contribute more to the separation of classes and association of views. For SELPCCA, this suggests that
#' these variables contribute more to the association between the two views. This plot can
#' only be generated for classification and association problems with 3 or more classes (SIDA and SIDANet),
#' or for CCA problems with two or more canonical correlation vectors requested (i.e. ncancorr > 1 for SELPCCA).
#'
#' @param fit the output from SIDA, SIDANet, and SELPCCA methods
#' @param color.line color to use for plotting direction vectors. Default is "darkgray".
#' @param keep.loadings numeric, specifying how many variables to represent on loadings plot. This is useful
#' in situations where the number of variables selected is large, and could clutter the plot. If this number is more
#' than the variables selected, it will be set to the maximum number of variables selected for each view.
#' Default is plotting all selected variables.
#' @param plotIt boolean, if TRUE, prints the plots. If FALSE, returns the ggplots as an object or list.  This is useful to customize the ggplots.
#' @details The function will either return nothing (if plotIt == TRUE), or return loading plots, one for each view.
#'
#' @return
#' \item{NULL}{}
#'
#' @seealso \code{\link{cvSIDA}} \code{\link{DiscriminantPlots}}
#' \code{\link{CorrelationPlots}}
#'
#' @references
#' Sandra E. Safo, Eun Jeong Min, and Lillian Haine (2023), Sparse Linear Discriminant
#' Analysis for Multi-view Structured Data, Biometrics.
#' Sandra E. Safo, Jeongyoun Ahn, Yongho Jeon, and Sungkyu Jung (2018),
#'  Sparse Generalized Eigenvalue Problem with Application to Canonical
#'  Correlation Analysis for Integrative Analysis of Methylation and Gene
#'  Expression Data. Biometrics
#'
#' @import ggplot2
#' @import ggthemes
#' @export
#' @examples
#' \dontrun{
#'data("sidanetData")
#'Xdata <- sidanetData[[1]]
#'Y <- sidanetData[[2]] #class membership already coded as 1,2,...
#'Xtestdata <- sidanetData[[3]]
#'Ytest <- sidanetData[[4]] #class membership already coded as 1,2,...
#'#edge information
#'myedges=sidanetData[[5]]
#'myedgeweight=sidanetData[[6]]
#'##---- call cross validation
#'mycvsidanet=cvSIDANet(Xdata,Y,myedges,myedgeweight,withCov=FALSE,plotIt=FALSE,Xtestdata=Xtestdata,
#'                      Ytest=Ytest, isParallel = FALSE)
#'LoadingsPlots(mycvsidanet,keep.loadings=c(3,3))
#'}

LoadingsPlots=function(fit,color.line="darkgray",
                       keep.loadings=NULL, plotIt = TRUE){
  loadings = Loadings(fit)
  
  if (is.null(keep.loadings)){
    warning("keep.loadings not specified, keeping all possible")
    keep.loadings = sapply(unique(loadings$View),
                            FUN = function(x){
                              sum(rowSums(abs(loadings[loadings$View == x,
                                                       c(1,2)])) != 0)
                            })
  }
  plots = lapply(unique(loadings$View),
                 FUN = function(jj){
                   xlab = ifelse(is(fit,"SIDA") | is(fit, "SIDANet"),
                                 paste("First Discriminant Vector for View", jj),
                                 paste("First Canonical Vector for View", jj))
                   ylab = ifelse(is(fit,"SIDA") | is(fit, "SIDANet"),
                                 paste("Second Discriminant Vector for View", jj),
                                 paste("Second Canonical Vector for View", jj))
                   title = paste("Loading Plot for View", jj)
                   loadings %>%
                     dplyr::filter(View == jj) %>%
                     dplyr::slice_head(n = keep.loadings[jj]) %>%
                     ggplot2::ggplot(aes(x = 0,
                                         xend = Loadings1, 
                                         y = 0,
                                         yend = Loadings2,
                                         label = Variable))+
                     geom_text(size = 4, aes(x = Loadings1,
                                             y = Loadings2)) +
                     geom_segment(linewidth=1,
                                  arrow=arrow(length=unit(0.3, "cm")), color = color.line) +
                     labs(x = xlab,
                          y = ylab,
                          title = title)+
                     theme_bw() +
                     theme(axis.line = element_line(colour = "black"),
                           panel.grid.major = element_blank(),
                           panel.grid.minor = element_blank()) +
                     geom_vline(xintercept = 0, color = "darkgrey") +
                     geom_hline(yintercept = 0, color = "darkgrey")+
                     ggthemes::theme_stata(scheme="s2manual")+
                     xlim(-1,1)
                 })
  if (plotIt){
    if (length(plots) == 1){
      print(plots[[1]])
    }else{
      gridExtra::grid.arrange(grobs = plots)
    }
    return()
  }
  plots
}

#' @title Loadings 
#'
#' @description function to get loadings for variables selected
#' by SIDA, SIDANet, and SELPCCA methods.
#'
#' @param fit the output from cvSIDA, cvSIDANet, or cvselpcca methods
#'
#' @return A data.frame with three columns. The first two columns are the non-zero loadings
#' The last column is the View from which the loadings were obtained. 
#'
Loadings = function(fit){
  if(is(fit,"SIDA") | is(fit, "SIDANet")){
    hatalpha=fit$hatalpha
  }else if(is(fit, "SELPCCA")){
    # selpcca needs conversion of hatalpha to loadings
    if(fit$method=="selpscca.pred"){
      #L=dim(hatalpha[[1]])[2]
      hatalpha=list(fit$selp.fit$hatalpha,
                    fit$selp.fit$hatbeta)
      L=length(hatalpha)
      for(j in 1:L){
        hatalpha[[j]]=qr.Q(qr(hatalpha[[j]]))
      }
    }else{ hatalpha=list(fit$hatalpha,fit$hatbeta)
    L=length(hatalpha)
    for(j in 1:L){
      hatalpha[[j]]=qr.Q(qr(hatalpha[[j]]))
    }}
  }
  
  ncomp=dim(hatalpha[[1]])[2]
  
  if(ncomp == 1){
    if(is(fit,"SIDA") | is(fit, "SIDANet")){
      stop("Loadings not applicable with one discriminant vector" , call. = FALSE)
    }else if(is(fit, "SELPCCA")){
      stop("Loadings not applicable with one CCA vector " , call. = FALSE)
    }
  }
  # the loadings are basically just the non-zero hatalpha. 
  # here we grab them, rbind them by View, and sort them by absolute value,
  # then toss the zeros s
  loadings = lapply(1:length(hatalpha),
                    FUN = function(jj){
                      loadings=as.data.frame(scale(hatalpha[[jj]],center=FALSE, scale=FALSE))
                      row.names(loadings) = colnames(fit$InputData[[jj]])
                      loading_order=order(rowSums(abs(hatalpha[[jj]])),
                                          decreasing = TRUE)
                      loadings = loadings[loading_order, ]
                      loadings = loadings[rowSums(abs(loadings)) > 0,]
                      colnames(loadings) = c("Loadings1","Loadings2")
                      loadings$View = jj
                      loadings$Variable = row.names(loadings)
                      loadings
                    }) %>%
    do.call("rbind", .)
  loadings
}


#' @title Biplots for Discriminant Scores or Canonical Correlation Variates for each View
#'
#' @description Biplots  to visualize discriminant scores/ canonical variates and how
#' selected variables contribute to the first and second discriminant (for SIDA and SIDANet)
#' or canonical correlation (for SELPCCA) vectors.  Variables farther from the origin and close to first or second axis
#' have higher impact on first or second discriminant/canonical vectors, respectively.
#' Variables farther from the origin and between both first and second axes have similar higher contributions to the
#' first and second discriminant/canonical correlation vectors. In both situations, for SIDA and SIDANet, this suggests that
#' these variables contribute more to the separation of classes and association of views. For SELPCCA, this suggests that
#' these variables contribute more to the association between the two views. This plot can
#' only be generated for classification and association problems with 3 or more classes (SIDA and SIDANet),
#' or for CCA problems with two or more canonical correlation vectors requested (i.e. ncancorr > 1 for SELPCCA).
#'
#' @param fit the output from SIDA, SIDANet, and SELPCCA methods
#' @param Y a vector of class membership for grouping canonical correlatoin variates and discriminant scores.
#' @param Xtest list of D entries containing test data. If not null, scores for biplots will be constructed for testing data.
#' @param color.palette  character vector of length K (number of classes), specifying the colors to use for the classes, respectively.
#' Defaults to shades of blue and orange (color.BlueOrange). Other option includes red and green combinations (color.GreenRed)
#' @param keep.loadings numeric vector of length D (number of views), specifying how many variables
#' to represent on loadings plot for each view. This is useful
#' in situations where the number of variables selected is large, and could clutter the plot. If this number is more
#' than the variables selected, it will be set to the maximum number of variables selected for each view.
#' Default is plotting all selected variables.
#' @param plotIt boolean, if TRUE, prints the plots. If FALSE, returns the ggplots as an object or list. This is useful to customize the ggplots. 

#' @details The function will either show the plots (if plotIt == TRUE) or return a list of loading plots, one for each view.
#'
#' @return
#' \item{NULL}{}
#'
#' @seealso \code{\link{cvSIDA}} \code{\link{DiscriminantPlots}}
#' \code{\link{CorrelationPlots}}
#'
#' @references
#' Sandra E. Safo, Eun Jeong Min, and Lillian Haine (2023), Sparse Linear Discriminant
#' Analysis for Multi-view Structured Data, Biometrics.
#' Sandra E. Safo, Jeongyoun Ahn, Yongho Jeon, and Sungkyu Jung (2018),
#'  Sparse Generalized Eigenvalue Problem with Application to Canonical
#'  Correlation Analysis for Integrative Analysis of Methylation and Gene
#'  Expression Data. Biometrics
#'
#' @import ggplot2
#' @import ggthemes
#' @export
#' @examples
#' \dontrun{
#'data("sidanetData")
#'Xdata <- sidanetData[[1]]
#'Y <- sidanetData[[2]] #class membership already coded as 1,2,...
#'Xtestdata <- sidanetData[[3]]
#'Ytest <- sidanetData[[4]] #class membership already coded as 1,2,...
#'#edge information
#'myedges=sidanetData[[5]]
#'myedgeweight=sidanetData[[6]]
#'##---- call cross validation
#'mycvsidanet=cvSIDANet(Xdata,Y,myedges,myedgeweight,withCov=FALSE,plotIt=FALSE,Xtestdata=Xtestdata,
#'                      Ytest=Ytest, isParallel = FALSE)
#'WithinViewBiplot(mycvsidanet,Y, color.palette=NULL,keep.loadings=c(3,3))
#'}

WithinViewBiplot=function(fit,Y,Xtest=NULL, color.palette=NULL,
                          keep.loadings=NULL, plotIt = TRUE){

  if(is(fit,"SIDA") | is(fit, "SIDANet")){
    hatalpha=fit$hatalpha
  }else if(is(fit, "SELPCCA")){
    if(fit$method=="selpscca.pred"){
      hatalpha=list(fit$selp.fit$hatalpha,fit$selp.fit$hatbeta)
      L=length(hatalpha)
      #L=dim(hatalpha[[1]])[2]
      for(j in 1:L){
        hatalpha[[j]]=qr.Q(qr(hatalpha[[j]]))
      }
    }else{ hatalpha=list(fit$hatalpha,fit$hatbeta)
    #L=dim(hatalpha[[1]])[2]
    L=length(hatalpha)
    for(j in 1:L){
      hatalpha[[j]]=qr.Q(qr(hatalpha[[j]]))
    }}

  }

  if(is.null(color.palette)){
    color.palette=color.BlueOrange(length(unique(Y)))
  }

  D <- length(hatalpha)
  L=dim(hatalpha[[1]])[2]
  Classes=factor(Y)
  ncomp=dim(hatalpha[[1]])[2]
  
  if(ncomp == 1){
    if(is(fit,"SIDA") | is(fit, "SIDANet")){
      stop("Loadings plot not applicable with one discriminant vector" , call. = FALSE)
    }else if(is(fit, "SELPCCA")){
      stop("Loadings plot not applicable with one CCA vector" , call. = FALSE)
    }
  }
  
  if (is.null(keep.loadings)){
    warning("keep.loadings not specified, keeping all possible")
    keep.loadings = sapply(hatalpha,
                           FUN = function(x){
                             sum(rowSums(abs(x)) != 0)
                           })
  }

    
  plots = lapply(1:D,
                 FUN = function(jj){
                   X1=as.data.frame(fit$InputData[[jj]])

                   hatalpha1=rowSums(abs(hatalpha[[jj]]))
                   hatalpha2=hatalpha1[order(hatalpha1,decreasing=TRUE)]
                   col1=order(hatalpha1,decreasing=TRUE)
                   
                   X1var.Ind=which(as.matrix(hatalpha1)!=0, arr.ind = TRUE)
                   

                     if(keep.loadings[[jj]]>sum(hatalpha1!=0)){
                       warning("keep.loadings is greater than maximum number of variables selected, setting to this maximum")
                       keep.loadings[[jj]]=sum(hatalpha1!=0)
                     }

                     myloadings=as.data.frame(scale(hatalpha[[jj]][col1[1:keep.loadings[jj]],],
                                                    center=FALSE, scale=FALSE))
                     X1var.ind=colnames(X1)[col1[1:keep.loadings[[jj]]]]
                     var.names=sub("\\;.*", "", X1var.ind)

        
                  if(is.null(Xtest)){
                     if(length(Y)!=dim(X1)[1]){
                       stop('size of Y must be the same as X')
                     }
                     Scores=cbind.data.frame(Y,scale(as.matrix(X1))%*%hatalpha[[jj]])
                   }else if(!is.null(Xtest)){
                     if(length(Y)==dim(Xtest[[jj]])[1]){
                       X1=Xtest[[jj]]
                     }
                     Scores=cbind.data.frame(Y,scale(as.matrix(X1))%*%hatalpha[[jj]])
                   }
                   
                   
                   if(keep.loadings[[jj]]==1){
                     myloadings=as.data.frame(t(myloadings))
                   }else{
                     myloadings=as.data.frame(myloadings)
                   }
                   
                   mxmax=max(abs(Scores[,2]))+20
                   mymax=max(abs(Scores[,3]))+20
                   
                    ggplot2::ggplot() +
                       geom_point(data = Scores[,-1], aes(shape=Classes,x = Scores[,2], y = Scores[,3], colour = Classes),size=4) +
                       stat_ellipse(aes(Scores[,2], Scores[,3], color=Classes, fill = Classes),type = "norm", geom = "polygon", alpha = 0.1)+
                       geom_segment(data = myloadings[,1:2], aes(x=0, y=0, xend=mxmax*myloadings[,1], yend=mymax*myloadings[,2]),
                                    linewidth=1,
                                    arrow=arrow(length=unit(0.3, "cm")), color = "black") +
                       scale_y_continuous(sec.axis = sec_axis(~./26)) +
                       geom_text(data = myloadings, aes(x=mxmax*myloadings[,1], y=mymax*myloadings[,2], label = var.names),
                                 size = 3.5, hjust = "outward", vjust = "outward") +
                       scale_colour_manual(values=color.palette) +
                       scale_fill_manual(values = color.palette) +
                       xlab(
                         if(is(fit,"SIDA") | is(fit, "SIDANet")){
                           paste(
                             "First Discriminant Score for View ", jj)
                         }else if(is(fit,"SELPCCA")){
                           paste("First Canonical Variate for View ",jj)
                         }
                         # paste(
                         # "First Discriminant Score for View ", jj)
                       ) +
                       ylab(
                         if(is(fit,"SIDA") | is(fit, "SIDANet")){
                           paste(
                             "Second Discriminant Score for View ", jj)
                         }else if(is(fit, "SELPCCA")){
                           paste("Second Canonical Variate for View ",jj)
                         }
                         #paste("Second Discriminant Score for View ", jj)
                       ) +
                       ggtitle(
                         if(is(fit,"SIDA") | is(fit, "SIDANet")){
                           paste("SIDA Biplot for View ",jj)
                         }else if(is(fit, "SELPCCA")){
                           paste("SELPCCA Biplot for View ",jj)
                         }
                       )+
                       theme_bw() +
                       theme(axis.line = element_line(colour = "black"),
                             panel.grid.major = element_blank(),
                             panel.grid.minor = element_blank()) +
                       geom_vline(xintercept = 0, color = "darkgrey") +
                       geom_hline(yintercept = 0, color = "darkgrey") +
                       ggthemes::theme_stata(scheme="s2manual")+
                       xlim(min(Scores[,2])-10,max(Scores[,2])+10)
                 })
  if (plotIt){
    if (length(plots) == 1){
      print(plots[[1]])
    }else{
      gridExtra::grid.arrange(grobs = plots)
    }
    return()
  }
  plots
}


#' @title Biplots for Discriminant Scores or Canonical Correlation Variates between pairs of views
#'
#' @description Biplots  to visualize discriminant scores/ canonical variates between pairs of views. It shows how
#' selected variables from the first and second discriminant (for SIDA and SIDANet)
#' or canonical correlation (for SELPCCA) vectors in a view is related to selected variables in another view.
#' Variables farther from the origin and close to first or second axis
#' have higher impact on first or second discriminant/canonical vectors, respectively.
#' Variables farther from the origin and between both first and second axes have similar higher contributions to the
#' first and second discriminant/canonical correlation vectors. In both situations, for SIDA and SIDANet, this suggests that
#' these variables contribute more to the separation of classes and association of views. For SELPCCA, this suggests that
#' these variables contribute more to the association between the two views. This plot can
#' only be generated for classification and association problems with 3 or more classes (SIDA and SIDANet),
#' or for CCA problems with two or more canonical correlation vectors requested (i.e. ncancorr > 1 for SELPCCA).
#' This plot shows the scores and loadings from pairs of views together. The scores are the
#' sum of scores for each view. Solid and dashed lines represent vectors for Views 1 and 2,
#' respectively.
#'
#' @param fit the output from SIDA, SIDANet, and SELPCCA methods
#' @param Y a vector of class membership for grouping canonical correlatoin variates and discriminant scores.
#' @param Xtest list of D entries containing test data. If not null, scores for biplots will be constructed for testing data.
#' @param color.palette  character vector of length K (number of classes), specifying the colors to use for the classes, respectively.
#' Defaults to shades of blue and orange (color.BlueOrange). Other option includes red and green combinations (color.GreenRed)
#' @param keep.loadings numeric vector of length D (number of views), specifying how many variables
#' to represent on loadings plot for each view. This is useful
#' in situations where the number of variables selected is large, and could clutter the plot. If this number is more
#' than the variables selected, it will be set to the maximum number of variables selected for each view.
#' Default is plotting all selected variables.
#' @param plotIt boolean, whether to print the result or just return it. default is TRUE.
#' @details The function will return loading plots, one for each view.
#'
#' @return
#' \item{NULL}{}
#'
#' @seealso \code{\link{cvSIDA}} \code{\link{DiscriminantPlots}}
#' \code{\link{CorrelationPlots}}
#'
#' @references
#' Sandra E. Safo, Eun Jeong Min, and Lillian Haine (2023), Sparse Linear Discriminant
#' Analysis for Multi-view Structured Data, Biometrics.
#' Sandra E. Safo, Jeongyoun Ahn, Yongho Jeon, and Sungkyu Jung (2018),
#'  Sparse Generalized Eigenvalue Problem with Application to Canonical
#'  Correlation Analysis for Integrative Analysis of Methylation and Gene
#'  Expression Data. Biometrics
#'
#' @import ggplot2
#' @import ggthemes
#' @export
#' @examples
#' \dontrun{
#'data("sidanetData")
#'Xdata <- sidanetData[[1]]
#'Y <- sidanetData[[2]] #class membership already coded as 1,2,...
#'Xtestdata <- sidanetData[[3]]
#'Ytest <- sidanetData[[4]] #class membership already coded as 1,2,...
#'#edge information
#'myedges=sidanetData[[5]]
#'myedgeweight=sidanetData[[6]]
#'##---- call cross validation
#'mycvsidanet=cvSIDANet(Xdata,Y,myedges,myedgeweight,withCov=FALSE,plotIt=FALSE,Xtestdata=Xtestdata,
#'                      Ytest=Ytest, isParallel = FALSE)
#'BetweenViewBiplot(mycvsidanet, Y,keep.loadings=c(3,3) )
#'}

BetweenViewBiplot=function(fit,Y, Xtest=NULL,color.palette=NULL,keep.loadings=NULL,plotIt = TRUE){
  if(is(fit,"SIDA") | is(fit, "SIDANet")){
    hatalpha=fit$hatalpha
  }else if(is(fit, "SELPCCA")){
    if(fit$method=="selpscca.pred"){
      hatalpha=list(fit$selp.fit$hatalpha,fit$selp.fit$hatbeta)
      #L=dim(hatalpha[[1]])[2]
      L=length(hatalpha)
      for(j in 1:L){
        hatalpha[[j]]=qr.Q(qr(hatalpha[[j]]))
      }
    }else{
      hatalpha=list(fit$hatalpha,fit$hatbeta)
      #L=dim(hatalpha[[1]])[2]
      L=length(hatalpha)
    for(j in 1:L){
      hatalpha[[j]]=qr.Q(qr(hatalpha[[j]]))
    }}

  }
  if(is.null(color.palette)){
    color.palette=color.BlueOrange(length(unique(Y)))
  }

  D <- length(hatalpha)

  L=dim(hatalpha[[1]])[2]



  # for(j in 1:L){
  #   hatalpha[[j]]=qr.Q(qr(hatalpha[[j]]))
  # }

  mycomb=combn(D,2) #pairwise combination
  ncomp=dim(hatalpha[[1]])[2]
  myloadings=list()
  


  Classes=factor(Y)

  ncomp=dim(hatalpha[[1]])[2]
  
  if(ncomp == 1){
    if(is(fit,"SIDA") | is(fit, "SIDANet")){
      stop("Loadings plot not applicable with one discriminant vector" , call. = FALSE)
    }else if(is(fit, "SELPCCA")){
      stop("Loadings plot not applicable with one CCA vecto " , call. = FALSE)
    }
  }
  
  if (is.null(keep.loadings)){
    warning("keep.loadings not specified, keeping all possible")
    keep.loadings = sapply(hatalpha,
                           FUN = function(x){
                             sum(rowSums(abs(x)) != 0)
                           })
  }
  
  plots = lapply(1:dim(mycomb)[2],
                 FUN = function(jj){
                   X1=as.data.frame(fit$InputData[[mycomb[1,jj]]])
                   X2=as.data.frame(fit$InputData[[mycomb[2,jj]]])
                   
                   if(is.null(Xtest)){
                     if(length(Y)!=dim(X1)[1]){
                       stop('size of Y must be the same as X')
                     }
                     X1=as.data.frame(fit$InputData[[mycomb[1,jj]]])
                     X2=as.data.frame(fit$InputData[[mycomb[2,jj]]])
                   }else if(!is.null(Xtest)){
                     Xtest[[jj]]=as.data.frame(Xtest[[jj]])
                     if(length(Y)==dim(Xtest[[jj]])[1]){
                       X1=as.data.frame(Xtest[[mycomb[1,jj]]])
                       X2=as.data.frame(Xtest[[mycomb[2,jj]]])
                     }else{
                       X1=as.data.frame(fit$InputData[[mycomb[1,jj]]])
                       X2=as.data.frame(fit$InputData[[mycomb[2,jj]]])
                     }
                   }
                   
                   hatalpha1=rowSums(abs(hatalpha[[mycomb[1,jj]]]))
                   col1=order(hatalpha1,decreasing=TRUE)
                   hatalpha2=rowSums(abs(hatalpha[[mycomb[2,jj]]]))
                   col2=order(hatalpha2,decreasing=TRUE)
                   
                   
                   if(!is.null(keep.loadings)){
                     if(keep.loadings[[mycomb[1,jj]]]>sum(hatalpha1!=0)){
                       warning("keep.loadings is greater than maximum number of variables selected, setting to this maximum")
                       keep.loadings[[mycomb[1,jj]]]=sum(hatalpha1!=0)
                     }
                     
                     if(keep.loadings[[mycomb[2,jj]]]>sum(hatalpha2!=0)){
                       warning("keep.loadings is greater than maximum number of variables selected, setting to this maximum")
                       keep.loadings[[mycomb[2,jj]]]=sum(hatalpha2!=0)
                     }
                     #for one view
                     mycolnames=sub("\\;.*", "", colnames(as.data.frame(fit$InputData[[mycomb[1,jj]]])))
                     var1.names <- mycolnames[col1[1:keep.loadings[[mycomb[1,jj]]]]]
                     #for another view
                     mycolnames=sub("\\;.*", "", colnames(as.data.frame(fit$InputData[[mycomb[2,jj]]])))
                     var2.names <- mycolnames[col2[1:keep.loadings[[mycomb[2,jj]]]]]
                     
                     myloadings[[1]]=as.data.frame(scale(hatalpha[[mycomb[1,jj]]][col1[1:keep.loadings[[mycomb[1,jj]]]],],center=FALSE,scale=FALSE))
                     myloadings[[2]]=as.data.frame(scale(hatalpha[[mycomb[2,jj]]][col2[1:keep.loadings[[mycomb[2,jj]]]],],center=FALSE,scale=FALSE))
                   }
                   
                   if(length(intersect(var1.names,var2.names))!=0){
                     var1.names <- paste(var1.names,mycomb[1,jj],sep="_")
                     var2.names <- paste(var2.names,mycomb[2,jj],sep="_")
                   }
                   
                   U=scale(as.matrix(X1))%*%hatalpha[[mycomb[1,jj]]]
                   V=scale(as.matrix(X2))%*%hatalpha[[mycomb[2,jj]]]
                   Z=U+V
                   Scores=cbind.data.frame(Y,Z)
                   
                   if(keep.loadings[[mycomb[1,jj]]]==1){
                     myloadings[[1]]=as.data.frame(t(myloadings[[1]]))
                   }
                   
                   if(keep.loadings[[mycomb[2,jj]]]==1){
                     myloadings[[2]]=as.data.frame(t(myloadings[[2]]))
                   }
                   
                   mxmax=max(abs(Scores[,2]))+25
                   mymax=max(abs(Scores[,3]))+25
                   

                   ggplot2::ggplot() +
                       geom_point(data = Scores[,-1], aes(shape=Classes,x = Scores[,2], y = Scores[,3], colour = Classes),size=4) +
                       stat_ellipse(aes(Scores[,2], Scores[,3], color=Classes, fill = Classes),type = "norm", geom = "polygon", alpha = 0.1)+
                       geom_segment(data = myloadings[[1]][,1:2], aes(x=0, y=0, xend=mxmax*myloadings[[1]][,1], yend=mymax*myloadings[[1]][,2],                                                       ),
                                    linewidth=1,
                                    arrow=arrow(length=unit(0.3, "cm")), color = "black") +
                       geom_text(data = myloadings[[1]], aes(x=mxmax*myloadings[[1]][,1], y=mymax*myloadings[[1]][,2], label = var1.names),
                                 size = 4, hjust = "outward", vjust = "outward") +
                       geom_segment(data = myloadings[[2]][,1:2], aes(x=0, y=0, xend=mxmax*myloadings[[2]][,1], yend=mymax*myloadings[[2]][,2],
                       ),
                       linewidth=2,linetype=2,
                       arrow=arrow(length=unit(0.3, "cm")), color = "red") +
                       geom_text(data = myloadings[[2]], aes(x=mxmax*myloadings[[2]][,1], y=mymax*myloadings[[2]][,2],
                                                             label = var2.names),
                                 size = 4, hjust = "outward", vjust = "outward") +
                       scale_y_continuous(sec.axis = sec_axis(~./26)) +
                       scale_colour_manual(values=color.palette) +
                       scale_fill_manual(values = color.palette) +
                       xlab(
                         if(is(fit,"SIDA") | is(fit, "SIDANet")){
                           paste(
                             "First Discriminant Score")
                         }else if(is(fit, "SELPCCA")){
                           paste("First Canonical Variate")
                         }
                       ) +
                       ylab(
                         if(is(fit,"SIDA") | is(fit, "SIDANet")){
                           paste(
                             "Second Discriminant Score")
                         }else if(is(fit, "SELPCCA")){
                           paste("Second Canonical Variate")
                         }
                         #paste("Second Discriminant Score for View ", jj)
                       ) +
                       ggtitle(
                         if(is(fit,"SIDA") | is(fit, "SIDANet")){
                           paste("SIDA Biplot for Views ",mycomb[1,jj], "and", mycomb[2,jj])
                         }else if(is(fit, "SELPCCA")){
                           paste("SELPCCA Biplot for Views ",mycomb[1,jj], "and", mycomb[2,jj])
                         }
                       )+
                       theme_bw() +
                       theme(axis.line = element_line(colour = "black"),
                             panel.grid.major = element_blank(),
                             panel.grid.minor = element_blank()) +
                       geom_vline(xintercept = 0, color = "darkgrey") +
                       geom_hline(yintercept = 0, color = "darkgrey") +
                       ggthemes::theme_stata(scheme="s2manual")+
                       xlim(min(Scores[,2])-5,max(Scores[,2])+5)

                 })
  if (plotIt){
    if (length(plots) == 1){
      print(plots[[1]])
    }else{
      gridExtra::grid.arrange(grobs = plots)
    }
    return()
  }
  plots
}


